{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aira-alice/Ai-Voice/blob/main/AI%20VOICE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code aims to make Gemini AI able to use voice input very well and produce very good voice output."
      ],
      "metadata": {
        "id": "iYOGiR48vtVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***run in order***"
      ],
      "metadata": {
        "id": "v829m0vsvdeC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UISXFEO-cfr"
      },
      "outputs": [],
      "source": [
        "# @title 1\n",
        "!pip install tts\n",
        "!pip install google-generativeai\n",
        "!pip install ffmpeg-python\n",
        "!pip install -U openai-whisper\n",
        "\n",
        "#untuk menyelesaikan error yang disebabkan oleh cutlet\n",
        "import locale\n",
        "from IPython.display import clear_output\n",
        "!pip install cutlet\n",
        "!pip install unidic-lite\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXwGVb1s-x8c"
      },
      "outputs": [],
      "source": [
        "# @title 2\n",
        "import google.generativeai as genai\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "import scipy\n",
        "import whisper\n",
        "import time\n",
        "\n",
        "import IPython\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMzV7mRf_S7c"
      },
      "outputs": [],
      "source": [
        "# @title 3\n",
        "import torch\n",
        "from TTS.api import TTS\n",
        "\n",
        "# Get device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# List available üê∏TTS models\n",
        "print(TTS().list_models())\n",
        "\n",
        "# Init TTS\n",
        "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n",
        "\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtMcXr3o6gxN"
      },
      "outputs": [],
      "source": [
        "# @title 4\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSctCsWancs5"
      },
      "outputs": [],
      "source": [
        "# @title 5\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import clear_output\n",
        "genai.configure(api_key=\"your Api Key\")\n",
        "\n",
        "prompt = \"role_system:name: Alisa\\nrole: Girlfriend\\npersonality: Tsundere girl\"\n",
        "\n",
        "\n",
        "# Set up the model\n",
        "generation_config = {\n",
        "  \"temperature\": 0.7,\n",
        "  \"top_p\": 1,\n",
        "  \"top_k\": 1,\n",
        "  \"max_output_tokens\": 2048,\n",
        "}\n",
        "\n",
        "safety_settings = [\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "  {\n",
        "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    \"threshold\": \"BLOCK_NONE\"\n",
        "  },\n",
        "]\n",
        "\n",
        "\n",
        "modelAi = genai.GenerativeModel(model_name='gemini-1.5-flash-latest',\n",
        "                              generation_config=generation_config,\n",
        "                              safety_settings=safety_settings,\n",
        "                              system_instruction=prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LVWD5UY__qB"
      },
      "outputs": [],
      "source": [
        "# please provide a voice sample to imitate\n",
        "\n",
        "cloneVoice = \"2B NEW.mp3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03D5Lf3mATUZ"
      },
      "outputs": [],
      "source": [
        "model = whisper.load_model(\"medium\")\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEnmbruwhSki"
      },
      "outputs": [],
      "source": [
        "# @title play with speech recognition\n",
        "while True :\n",
        "  audio, sr = get_audio()\n",
        "  scipy.io.wavfile.write('record.wav', sr, audio)\n",
        "\n",
        "  result = model.transcribe(\"record.wav\",language=\"id\")\n",
        "\n",
        "  prompt_parts = (result[\"text\"])\n",
        "  print(\"User : \" + prompt_parts)\n",
        "  response = modelAi.generate_content(prompt_parts)\n",
        "\n",
        "  print(\"AI : \" + response.text )\n",
        "\n",
        "\n",
        "\n",
        "  tts.tts_to_file(text= response.text , speaker_wav=cloneVoice, language=\"ja\", file_path=\"output.wav\")\n",
        "\n",
        "  time.sleep(1)\n",
        "  wn = Audio('output.wav', autoplay=True)\n",
        "  display(wn)\n",
        "  inp = input(\"\")\n",
        "  if inp == \"break\" :\n",
        "    clear_output()\n",
        "    break\n",
        "  clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0_xYYvDre9e"
      },
      "outputs": [],
      "source": [
        "# @title play input teks\n",
        "while True :\n",
        "  #audio, sr = get_audio()\n",
        "  #scipy.io.wavfile.write('record.wav', sr, audio)\n",
        "  #result = model.transcribe(\"record.wav\")\n",
        "\n",
        "  #prompt_parts = (result[\"text\"])\n",
        "  prompt_parts = input(\"User : \")\n",
        "  print(\"User : \" + prompt_parts)\n",
        "  response = modelAi.generate_content(prompt_parts)\n",
        "\n",
        "\n",
        "  print(\"AI : \" + response.text )\n",
        "\n",
        "\n",
        "\n",
        "  tts.tts_to_file(text= response.text , speaker_wav=cloneVoice, language=\"ja\", file_path=\"output.wav\")\n",
        "\n",
        "  time.sleep(1)\n",
        "  wn = Audio('output.wav', autoplay=True)\n",
        "  display(wn)\n",
        "  inp = input(\"\")\n",
        "  if inp == \"break\" :\n",
        "    clear_output()\n",
        "    break\n",
        "  clear_output()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNj8WBPp5HMpFOYy7TF1A6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}